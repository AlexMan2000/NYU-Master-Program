{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de628fd",
   "metadata": {},
   "source": [
    "# Shifting and scaling: general univariate Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99363750",
   "metadata": {},
   "source": [
    "Let $\\tilde{x} \\sim N(0, 1)$. In this section, we will shift $\\tilde{x}$ by  $\\mu \\in R$, and scale it by $\\sigma \\in R^+$ in order to obtain a general univariate Gaussian $\\tilde{z} \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "\n",
    "The pdf of $\\tilde{x}$ is $$p_{\\tilde{x}}(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right).$$\n",
    "\n",
    "Let's plot the kernel density estimate (KDE) of $X$ by using a library function. In the following section, we will implement the KDE ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec8995",
   "metadata": {},
   "source": [
    "Here is the initial setup code where we import our libraries, and set up the random number generator (RNG) for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc68ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "seed = 0\n",
    "rng = np.random.RandomState(seed)\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a8733",
   "metadata": {},
   "source": [
    "When plotting, it is good practice to create references to the figure and axis objects by calling `plt.subplots`. This will make it easy to overlay charts, and combine multiple plots in a grid if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e05974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(ax, x, label):\n",
    "    kde = gaussian_kde(x)\n",
    "    x_sorted = np.sort(x)\n",
    "    ax.plot(np.sort(x_sorted), kde(x_sorted), label=label)\n",
    "    ax.set_xlabel(\"value\")\n",
    "    ax.set_ylabel(\"density\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "x = rng.normal(size=n)\n",
    "plot_kde(ax, x, r\"$p_{\\tilde{x}}(x)$ estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a8207",
   "metadata": {},
   "source": [
    "Let's compare the estimate to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_x(x):\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-(x ** 2 / 2))\n",
    "\n",
    "x_range = np.linspace(x.min(), x.max(), 100)\n",
    "ax.plot(x_range, pdf_x(x_range), label=r\"$p_{\\tilde{x}}(x)$ truth\")\n",
    "ax.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7545a",
   "metadata": {},
   "source": [
    "Now, let's shift $\\tilde{x}$ by $\\mu$ and call it $\\tilde{y}$. That is, $\\tilde{y} = \\tilde{x} + \\mu$. We can obtain the pdf of $\\tilde{y}$ by substituting $\\tilde{x} = \\tilde{y} - \\mu$ in the pdf of $\\tilde{x}$. We have $$p_{\\tilde{y}}(y) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(y - \\mu)^2}{2}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7104c7b",
   "metadata": {},
   "source": [
    "Let's compute the KDE of $\\tilde{y}$, and compare it to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 5\n",
    "y = x + mu\n",
    "\n",
    "def pdf_y(y, mu):\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-((y - mu) ** 2 / 2))\n",
    "\n",
    "plot_kde(ax, y, label=r\"$p_{\\tilde{y}}(y)$ estimate\")\n",
    "y_range = np.linspace(y.min(), y.max(), 100)\n",
    "ax.plot(y_range, pdf_y(y_range, mu), label=r\"$p_{\\tilde{y}}(y)$ truth\")\n",
    "ax.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154231c",
   "metadata": {},
   "source": [
    "Finally, let's scale $\\sigma$ to define $\\tilde{z} = \\sigma x + \\mu$. Can we substitute $x = \\frac{z - \\mu}{\\sigma}$ to obtain the pdf of $\\tilde{z}$? This would be $$p'_{\\tilde{z}}(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(z - \\mu)^2}{2\\sigma^2}\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5710a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "z = sigma * x + mu\n",
    "\n",
    "def qz(z, mu, sigma):\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-((z - mu) ** 2 / (2 * sigma ** 2)))\n",
    "\n",
    "figz, axz = plt.subplots(1, 1)\n",
    "plot_kde(axz, z, label=r\"$p_{\\tilde{z}}(z)$ estimate\")\n",
    "z_range = np.linspace(z.min(), z.max(), 100)\n",
    "axz.plot(z_range, qz(z_range, mu, sigma), label=r\"$q_{\\tilde{z}}(z)$\")\n",
    "axz.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103999db",
   "metadata": {},
   "source": [
    "In this case, our KDE estimate and ground truth are inconsistent. What happened? We just scaled $\\tilde{x}$ and plugged it back into $p_{\\tilde{x}}(x)$ (after subtracting out $\\mu$) to obtain $q_{\\tilde{z}}(z)$. $q_{\\tilde{z}}(z)$ is no longer a valid pdf, since it violates Theorem 3.18 by no longer integrating to one over its domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a08b0c",
   "metadata": {},
   "source": [
    "We can normalize $q_{\\tilde{z}}(z)$ to turn it into $p_{\\tilde{z}}(z)$, i.e. $$p_{\\tilde{z}}(z) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left(\\frac{-(z - \\mu)^2}{2 \\sigma^2}\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d029c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_z(z, mu, sigma):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-((z - mu) ** 2 / (2 * sigma ** 2)))\n",
    "\n",
    "axz.plot(z_range, pdf_z(z_range, mu, sigma), label=r\"$p_{\\tilde{z}}(z)$ truth\")\n",
    "axz.legend()\n",
    "figz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a482391",
   "metadata": {},
   "source": [
    "Let's see it alongside $\\tilde{x}$ and $\\tilde{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fddc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(ax, z, label=r\"$p_{\\tilde{z}}(z)$ estimate\")\n",
    "ax.plot(z_range, pdf_z(z_range, mu, sigma), label=r\"$p_{\\tilde{z}}(z)$ truth\")\n",
    "ax.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c79ff3",
   "metadata": {},
   "source": [
    "# Implementing the Gaussian KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cea202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_truth(ax, x, label):\n",
    "    kde = gaussian_kde(x)\n",
    "    x_sorted = np.sort(x)\n",
    "    ax.plot(np.sort(x_sorted), kde(x_sorted), label=label)\n",
    "\n",
    "def gaussian_kernel(dist):\n",
    "    return 1 / np.sqrt(2 * np.pi) * np.exp(-dist**2 / 2)\n",
    "    \n",
    "x = rng.normal(size=n)\n",
    "\n",
    "h = 0.5\n",
    "a_range = np.linspace(x.min(), x.max(), 100)\n",
    "\n",
    "kde_estimates = [gaussian_kernel((a - x) / h).sum() / (n * h) for a in a_range]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(a_range, kde_estimates, label=\"Estimate\")\n",
    "plot_kde(ax, x, \"Ground truth\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff82b4c",
   "metadata": {},
   "source": [
    "# Inverse transform sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83bd88",
   "metadata": {},
   "source": [
    "It is very useful to be able to sample from a given distribution $\\tilde{x} \\sim p_{\\tilde{x}}(x)$. Here we discuss a method called *inverse transform sampling* which transforms samples from $\\mathcal{U}(0, 1)$ into samples from $p_{\\tilde{x}}(x)$.\n",
    "\n",
    "It assumes two things: (i) that we can sample from $\\mathcal{U}(0, 1)$, and (ii) we can compute the inverse cdf of $\\tilde{x}$ analytically.\n",
    "\n",
    "Let's first consider the case where $\\tilde{x} \\sim \\mathcal{U}(a, b)$. The CDF is $F_{\\tilde{x}}(x) = \\frac{x - a}{b - a}$. Therefore, the inverse cdf is $$\\begin{align*}u &= \\frac{x - a}{b - a}\\\\ u(b - a) &= x - a\\\\ x &= u(b - a) + a.\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4fb07",
   "metadata": {},
   "source": [
    "Here's the initial setup code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16bcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = rng.uniform(size=n)\n",
    "\n",
    "def plot_samples(x_transformed, x_real):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    axes[0].hist(x_transformed)\n",
    "    axes[1].hist(x_real, color=\"orange\")\n",
    "\n",
    "    axes[0].set_title(\"Samples from inv cdf\")\n",
    "    axes[1].set_title(\"Samples from scipy\")\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(r\"$x$\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9be8a",
   "metadata": {},
   "source": [
    "Let's sample from $\\mathcal{U}(2, 5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408eca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 2, 5\n",
    "\n",
    "def inv_cdf(u, a, b):\n",
    "    return u * (b - a) + a\n",
    "\n",
    "x_transformed = inv_cdf(u, a, b)\n",
    "x_real = rng.uniform(a, b, size=n)\n",
    "\n",
    "plot_samples(x_transformed, x_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511004d5",
   "metadata": {},
   "source": [
    "Next, let's consider the case where $\\tilde{x}$ comes from an exponential distribution. The cdf is $F_{\\tilde{x}}(x) = 1 - \\exp(-\\lambda x)$. To compute the inverse cdf, we can write\n",
    "$$\\begin{align*}u &= 1 - \\exp(-\\lambda x)\\\\ u - 1 &= \\exp(-\\lambda x)\\\\ 1 - u &= \\exp(-\\lambda x)\\\\ \\ln(1 - y) &= \\lambda x\\\\ x &= \\frac{\\ln(1 - y)}{-\\lambda}\\end{align*}.$$\n",
    "\n",
    "This means that if we take $u \\in [0, 1]$ as the output of the cdf, it gives us the value of $x$ such that $P(\\tilde{x} \\leq x) = u$.\n",
    "\n",
    "Let's use this to sample from $\\tilde{x} \\sim \\text{Exp}(1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe026ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_cdf_exp(u, lam):\n",
    "    return np.log(1 - u) / -lam\n",
    "\n",
    "lam = 1\n",
    "\n",
    "x_transformed = inv_cdf_exp(u, lam)\n",
    "x_real = rng.exponential(scale=lam, size=n)\n",
    "\n",
    "plot_samples(x_transformed, x_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
