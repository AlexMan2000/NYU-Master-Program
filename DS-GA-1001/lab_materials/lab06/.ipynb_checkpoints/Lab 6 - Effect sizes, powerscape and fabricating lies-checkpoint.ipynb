{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dad8b1",
   "metadata": {},
   "source": [
    "# Lab 6: Significance is not enough\n",
    "\n",
    "Introduction to Data Science (DS-GA1001)\n",
    "\n",
    "Code by: Stephen Spivack (ss7726@nyu.edu), Pascal Wallisch (pascalwallisch@nyu.edu)\n",
    "\n",
    "Date: 10-12-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10193ddb",
   "metadata": {},
   "source": [
    "## 1) Mean differences, effect sizes and significance\n",
    "\n",
    "### Effect sizes as salvation? take home message: The same effect size can correspond to dramatically different p values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e3fec",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "numReps = 500 # Number of repetitions in our simulation\n",
    "sata = np.empty([numReps,3,2]) # Initialize empty 3D array for sata\n",
    "sata[:] = np.NaN # then convert to NaN \n",
    "PvsE = np.empty([numReps,5]) # Initialize empty 2D array for PvsE\n",
    "PvsE[:] = np.NaN # then convert to NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fcb24",
   "metadata": {},
   "source": [
    "Generate and analyze sata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(numReps): # loop through each rep\n",
    "    p = 0 # set p to 0\n",
    "    while abs(p - 0.04) > 0.01: # Find datasets that are just about significant\n",
    "        # main idea: all the p-vals will be just under 0.05 - but we will see differences, for instance in cohen's d\n",
    "        temp = np.random.normal(0,1,[3,2]) # Draw n = 3 (mu = 0, sigma = 1)\n",
    "        t,p = stats.ttest_rel(temp[:,0],temp[:,1]) # paired t-test\n",
    "    sata[ii] = temp # store temp in sata array\n",
    "    \n",
    "    # sample size:\n",
    "    PvsE[ii,0] = len(sata[ii,:,:]) # take the length of the z-stack dimension\n",
    "    \n",
    "    # significance level:\n",
    "    t,p = stats.ttest_rel(sata[ii,:,0],sata[ii,:,1]) # paired t-test\n",
    "    PvsE[ii,1] = p \n",
    "    \n",
    "    # effect size (computing cohen's d by hand):\n",
    "    mean1 = np.mean(sata[ii,:,0]) # mean of sample 1\n",
    "    mean2 = np.mean(sata[ii,:,1]) # mean of sample 2\n",
    "    std1 = np.std(sata[ii,:,0]) # std of sample 1\n",
    "    std2 = np.std(sata[ii,:,1]) # std of sample 2\n",
    "    n1 = len(sata[ii,:,0]) # size of sample 1\n",
    "    n2 = len(sata[ii,:,1]) # size of sample 2\n",
    "    numerator = abs(mean1-mean2) # absolute value of mean difference\n",
    "    denominator = np.sqrt((std1**2)/2 + (std2**2)/2) # pooled std\n",
    "    d = numerator/denominator\n",
    "    PvsE[ii,2] = d\n",
    "    \n",
    "    # mean differences:\n",
    "    PvsE[ii,3] = abs(np.mean(sata[ii,:,0]) - np.mean(sata[ii,:,1]))\n",
    "    \n",
    "    # pooled standard deviation:\n",
    "    PvsE[ii,4] = np.sqrt((std1**2)/2 + (std2**2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b96c2a",
   "metadata": {},
   "source": [
    "Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(2,3,1)\n",
    "plt.hist(PvsE[:,1],20)\n",
    "plt.title('p value')\n",
    "plt.subplot(2,3,2)\n",
    "plt.hist(PvsE[:,2],20)\n",
    "plt.title('cohens d')\n",
    "plt.subplot(2,3,3)\n",
    "plt.hist(PvsE[:,3],20)\n",
    "plt.title('mean diff')\n",
    "plt.subplot(2,3,4)\n",
    "plt.hist(PvsE[:,4],20)\n",
    "plt.title('pooled sd')\n",
    "plt.subplot(2,3,5)\n",
    "plt.plot(PvsE[:,2],PvsE[:,3],'o',markersize=.5)\n",
    "plt.xlabel('cohens d')\n",
    "plt.ylabel('abs mean diff')\n",
    "plt.subplot(2,3,6)\n",
    "plt.plot(PvsE[:,2],PvsE[:,4],'o',markersize=.5)\n",
    "plt.xlabel('cohens d')\n",
    "plt.ylabel('pooled sd')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee696292",
   "metadata": {},
   "source": [
    "## 2) Distributions of p values assuming true vs. false null hypothesis (H0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9ed5a",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce260ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 100\n",
    "numReps = int(1e4) # Number of repetitions in our simulation\n",
    "meanDifference = 0.25 # Actual difference in sample means. Try 0 and other values.\n",
    "alpha = 0.05 #The alpha level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b66610",
   "metadata": {},
   "source": [
    "Generate some sata and run the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ea533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw from a random normal distribution with zero mean:\n",
    "sata1 = np.random.normal(0,1,[sampleSize,numReps])\n",
    "\n",
    "# Our 2nd sample. Same distribution, different mean:\n",
    "sata2 = np.random.normal(0,1,[sampleSize,numReps]) + meanDifference\n",
    "\n",
    "# Run a t-test, a lot of times:\n",
    "t = np.empty([numReps,1]) # initialize empty 2D array for t\n",
    "t[:] = np.NaN # then convert to NaN\n",
    "p = np.empty([numReps,1]) # initialize empty 2D array for p\n",
    "p[:] = np.NaN # then convert to NaN\n",
    "for ii in range(numReps): # loop through each rep\n",
    "    t[ii],p[ii] = stats.ttest_ind(sata1[:,ii],sata2[:,ii]) # do the t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d54d2",
   "metadata": {},
   "source": [
    "Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p,100)\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3abe33",
   "metadata": {},
   "source": [
    "Determine proportion significant results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a98348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = len(np.argwhere(p<alpha).flatten())/len(p)\n",
    "print('Proportion significant results:',Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bbef74",
   "metadata": {},
   "source": [
    "## 3) The powerscape - generalizing effect sizes and sample sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a2b98",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "popSize = int(1e3) # Size of the population\n",
    "nnMax = 250 # Maximal sample size to be considered\n",
    "nnMin = 5 # Minimal sample size to be considered\n",
    "sampleSize = np.linspace(nnMin,nnMax,246) # array of each sample size\n",
    "effectSize = np.linspace(0,1.5,31) # From 0 to 1.5, in .05 increments\n",
    "# As std is one, effect_size will be in units of std\n",
    "pwr = np.empty([len(sampleSize),len(effectSize)]) # initialize power array\n",
    "pwr[:] = np.NaN # then conver to nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d967270",
   "metadata": {},
   "source": [
    "Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612022ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for es in range(len(effectSize)): # loop through each effect size (31 total)\n",
    "    A = np.random.normal(0,1,[popSize,2]) # Get the population of random \n",
    "    # numbers for each effect size - 2 columns, 1000 rows\n",
    "    A[:,1] = A[:,1] + effectSize[es] # Add effect size to 2nd one\n",
    "    for n in range(len(sampleSize)): # loop through each sample size\n",
    "        mm = int(2e1) # Number of repeats\n",
    "        significances = np.empty([mm,1]) # preallocate\n",
    "        significances[:] = np.NaN\n",
    "        for ii in range(mm): # Do this mm times for each one\n",
    "            sampInd = np.random.randint(0,popSize,[n+5,2]) # subsample\n",
    "            # we add 5 to n because n is indexed at 0 but our min n is 5\n",
    "            drawnSample = np.empty([n+5,2]) # initialize empty\n",
    "            # drawn_sample starts as 5x2 and with each iteration adds one row\n",
    "            drawnSample[:] = np.NaN # convert to NaN\n",
    "            drawnSample[:,0] = A[sampInd[:,0],0] \n",
    "            drawnSample[:,1] = A[sampInd[:,0],1]\n",
    "            t,p = stats.ttest_ind(drawnSample[:,0],drawnSample[:,1])\n",
    "            if p < .05: # assuming our alpha is 0.05\n",
    "                significances[ii,0] = 1 # if significant, assign 1\n",
    "            else:\n",
    "                significances[ii,0] = 0 # if ~significant, assign 0\n",
    "        pwr[n,es] = sum(significances)/mm*100 # compute power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274755f4",
   "metadata": {},
   "source": [
    "Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cecba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(pwr) #create a pseudocolor plot with a non-regular rectangular grid\n",
    "plt.colorbar()\n",
    "plt.xlabel('real effect size (mean diff in SD')\n",
    "plt.ylabel('sample size (n)')\n",
    "plt.title('powerscape t-test') # color represents significant effects\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41cf0b",
   "metadata": {},
   "source": [
    "### 4) Flexible stopping - an example of p-hacking. The p-value *always* gets below alpha, eventually. Just by flexible stopping alone.\n",
    "\n",
    "### \"This is the weaponization of sampling error for bad ends - to pursue careerist goals that hurt society\"...Lascap Foxman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d82996",
   "metadata": {},
   "source": [
    "Init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5 # Starting n - here, 5\n",
    "p = 1 # Starting p - value - let's say 1\n",
    "alpha = 0.05 # What is our alpha level?\n",
    "droppingToo = 0 # If this flag is on, we don't just flexibly stop, we also drop people, if they increase the p-value\n",
    "\n",
    "nCont = np.array([]) # Initialize the container that will hold our ns \n",
    "pCont = np.array([]) # And one for the corresponding p-values\n",
    "data = np.random.normal(0,1,[n,2]) # %Randomly draw data from n people from a normal distribution, in \n",
    "# both conditions, like for an A/B test. Note that there is no effect here. Just randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8b4ab",
   "metadata": {},
   "source": [
    "Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c47935",
   "metadata": {},
   "outputs": [],
   "source": [
    "while p > alpha: # As long as the p-value is not significant yet\n",
    "    t,p = stats.ttest_ind(data[:,0],data[:,1]) # Do a t-test on the data, columns = A vs. B\n",
    "    nCont = np.append(nCont,n) # Capture the n for this test \n",
    "    pCont = np.append(pCont,p) # And the corresponding p-value\n",
    "    tempP = 1  # Initialize a new p-value\n",
    "    if droppingToo == 0: # Flexible stopping only\n",
    "        data = np.concatenate((data,np.random.normal(0,1,[1,2])),axis=0) # Then add data from 1 (one) new participant to the dataset, one per condition\n",
    "    elif droppingToo == 1:\n",
    "        while tempP > p: # While our new p is larger than our old p\n",
    "            tempData = np.concatenate((data,np.random.normal(0,1,[1,2])),axis=0) # Try new people until they lower our p-value. Obviously, there is something wrong with those who don't help our p-value\n",
    "            t,tempP = stats.ttest_ind(tempData[:,0],tempData[:,1]) # Do a t-test on the stop with the provisional new data, if they make our p-value worse, we don't even enter them into the dataset\n",
    "            break\n",
    "        data = np.concatenate((data,tempData),axis=0) # Add them to the dataset if (and only if) they lower the p-value\n",
    "    n = n + 1 # Update the n accordingly (we could simply get it from length(n), but whatever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b952d04",
   "metadata": {},
   "source": [
    "Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nCont,pCont,color='red',linewidth=0.5)\n",
    "plt.plot(nCont,pCont,'o',color='black',markersize=2)\n",
    "plt.plot([5,n],[alpha,alpha],color='black',linewidth=0.5,linestyle='dashed') # draw decision threshold as a line\n",
    "plt.title('Final p-value = {:.3f}'.format(p))\n",
    "plt.xlabel('Participants')\n",
    "plt.xlim(5,n)\n",
    "plt.ylabel('p')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4a422",
   "metadata": {},
   "source": [
    "### 5) Last thing for fun: effect of n and number of simulations in the bootstrap - it is all related to power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0845c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take home message:\n",
    "from scipy.stats import bootstrap # did everyone get this working? try: pip install --upgrade scipy\n",
    "sata = np.random.normal(0,1,10000)\n",
    "num_samples = [25, 50, 100, 1000, 10000]\n",
    "num_simulations = [25, 50, 100, 1000, 10000]\n",
    "counter = 1\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(len(num_samples)):\n",
    "    for j in range(len(num_simulations)):\n",
    "        random_samples = sata[np.random.randint(0, 10000, num_samples[i])]\n",
    "        print('num_samples:', num_samples[i])\n",
    "        print('num_simulations:', num_simulations[j])\n",
    "        print(bootstrap((list(random_samples),), np.mean, n_resamples=num_simulations[j], confidence_level=0.95))\n",
    "        plt.subplot(5,5,counter)\n",
    "        plt.hist(random_samples, density=True, color='lightgrey')\n",
    "        plt.vlines(np.mean(random_samples), 0, 1)\n",
    "        counter+=1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
